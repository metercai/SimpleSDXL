{
  "107": {
    "inputs": {
      "text": [
        "305",
        0
      ],
      "clip": [
        "123",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "108": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "112": {
    "inputs": {
      "guidance": 2.5,
      "conditioning": [
        "107",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "123": {
    "inputs": {
      "clip_name1": "t5xxl_fp8_e4m3fn.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "187": {
    "inputs": {
      "object_to_patch": "diffusion_model",
      "residual_diff_threshold": 0.12,
      "start": 0,
      "end": 1,
      "max_consecutive_cache_hits": -1,
      "model": [
        "197",
        0
      ]
    },
    "class_type": "ApplyFBCacheOnModel",
    "_meta": {
      "title": "Apply First Block Cache"
    }
  },
  "189": {
    "inputs": {
      "samples": [
        "217:4",
        0
      ],
      "vae": [
        "108",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "196": {
    "inputs": {
      "unet_name": "flux-hyp8-Q5_K_M.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "197": {
    "inputs": {
      "model": [
        "196",
        0
      ]
    },
    "class_type": "DifferentialDiffusion",
    "_meta": {
      "title": "Differential Diffusion"
    }
  },
  "207": {
    "inputs": {
      "blur_radius": 4,
      "sigma": 2,
      "image": [
        "313",
        0
      ]
    },
    "class_type": "ImageBlur",
    "_meta": {
      "title": "Image Blur"
    }
  },
  "208": {
    "inputs": {
      "pixels": [
        "284",
        0
      ],
      "vae": [
        "108",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "232": {
    "inputs": {
      "value": [
        "236",
        1
      ]
    },
    "class_type": "easy int",
    "_meta": {
      "title": "aspect_ratios_width"
    }
  },
  "236": {
    "inputs": {
      "clip_skip": -1,
      "width": 1536,
      "height": 1024,
      "swap": false,
      "batch_size": 1,
      "positive": "",
      "negative": "",
      "seed": 837688174129972,
      "steps": 10,
      "cfg": 30,
      "denoise": 1
    },
    "class_type": "Co_Input_Zho",
    "_meta": {
      "title": "i2i_overall_input"
    }
  },
  "238": {
    "inputs": {
      "conditioning": [
        "107",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "244": {
    "inputs": {
      "images": [
        "189",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "result_image"
    }
  },
  "245": {
    "inputs": {
      "purge_cache": true,
      "purge_models": true,
      "anything": [
        "189",
        0
      ]
    },
    "class_type": "LayerUtility: PurgeVRAM",
    "_meta": {
      "title": "LayerUtility: Purge VRAM"
    }
  },
  "247": {
    "inputs": {
      "value": 28
    },
    "class_type": "easy int",
    "_meta": {
      "title": "K1 steps"
    }
  },
  "248": {
    "inputs": {
      "value": 8
    },
    "class_type": "easy int",
    "_meta": {
      "title": "K2 steps"
    }
  },
  "283": {
    "inputs": {
      "strength": 0,
      "brightness": 0,
      "contrast": 5,
      "saturation": 0,
      "red": 0,
      "green": 0,
      "blue": 0,
      "mode": "RGB",
      "image": [
        "207",
        0
      ]
    },
    "class_type": "LayerColor: AutoAdjustV2",
    "_meta": {
      "title": "LayerColor: AutoAdjust V2"
    }
  },
  "284": {
    "inputs": {
      "strength": 100,
      "brightness": 0,
      "contrast": 0,
      "saturation": 0,
      "red": 0,
      "green": 0,
      "blue": 0,
      "mode": "RGB",
      "image": [
        "283",
        0
      ]
    },
    "class_type": "LayerColor: AutoAdjustV2",
    "_meta": {
      "title": "LayerColor: AutoAdjust V2"
    }
  },
  "290": {
    "inputs": {
      "pixels": [
        "308",
        0
      ],
      "vae": [
        "297",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "291": {
    "inputs": {
      "width": [
        "300",
        0
      ],
      "height": [
        "300",
        0
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "309:1",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "292": {
    "inputs": {
      "samples": [
        "307",
        0
      ],
      "vae": [
        "297",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "294": {
    "inputs": {
      "images": [
        "292",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "mask_image1"
    }
  },
  "295": {
    "inputs": {
      "prompt": [
        "296",
        0
      ],
      "find1": "sepia",
      "replace1": "",
      "find2": "yellowing",
      "replace2": "",
      "find3": "fuzzy",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "296": {
    "inputs": {
      "prompt": [
        "310",
        0
      ],
      "find1": "monochrome",
      "replace1": "",
      "find2": "greyscale",
      "replace2": "",
      "find3": "black and white",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "297": {
    "inputs": {
      "ckpt_name": "LEOSAM_HelloWorldXL_70.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "base_model"
    }
  },
  "298": {
    "inputs": {
      "strength": 0,
      "brightness": 0,
      "contrast": 5,
      "saturation": 0,
      "red": 0,
      "green": 0,
      "blue": 0,
      "mode": "RGB",
      "image": [
        "299",
        0
      ]
    },
    "class_type": "LayerColor: AutoAdjustV2",
    "_meta": {
      "title": "LayerColor: AutoAdjust V2"
    }
  },
  "299": {
    "inputs": {
      "blur_radius": 4,
      "sigma": 2,
      "image": [
        "291",
        0
      ]
    },
    "class_type": "ImageBlur",
    "_meta": {
      "title": "Image Blur"
    }
  },
  "300": {
    "inputs": {
      "value": 1536
    },
    "class_type": "easy int",
    "_meta": {
      "title": "aspect_ratios_width"
    }
  },
  "302": {
    "inputs": {
      "width": 512,
      "height": 512,
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "306",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "303": {
    "inputs": {
      "lora_name": "Hyper-SDXL-8steps-lora.safetensors",
      "strength_model": 1,
      "model": [
        "297",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "304": {
    "inputs": {
      "text": [
        "305",
        0
      ],
      "clip": [
        "297",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "305": {
    "inputs": {
      "prompt": [
        "295",
        0
      ],
      "find1": "there are no traces of old photos such as",
      "replace1": "",
      "find2": "old photos",
      "replace2": "photo",
      "find3": "old photo",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "306": {
    "inputs": {
      "image": "2-ÁæéÂõΩÁî∑ÈùíÂπ¥.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "i2i_ip_image1"
    }
  },
  "307": {
    "inputs": {
      "seed": 633067730008468,
      "steps": [
        "248",
        0
      ],
      "cfg": 0.8,
      "sampler_name": "euler_ancestral_cfg_pp",
      "scheduler": "sgm_uniform",
      "denoise": 1,
      "model": [
        "303",
        0
      ],
      "positive": [
        "301:1",
        0
      ],
      "negative": [
        "301:1",
        1
      ],
      "latent_image": [
        "290",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler1"
    }
  },
  "308": {
    "inputs": {
      "strength": 100,
      "brightness": 0,
      "contrast": 0,
      "saturation": 0,
      "red": 0,
      "green": 0,
      "blue": 0,
      "mode": "RGB",
      "image": [
        "298",
        0
      ]
    },
    "class_type": "LayerColor: AutoAdjustV2",
    "_meta": {
      "title": "LayerColor: AutoAdjust V2"
    }
  },
  "310": {
    "inputs": {
      "positive": "ultra-high resolution, fine details, precise focus, sharp edges, smooth lines, natural colors, rich light and shadow, pure image, professional raw photo, analog photo,      \nan old photograph of a young man in a baseball uniformsolo, looking at viewer, short hair, black hair, 1boy, monochrome, upper body, greyscale, male focus, uniform, black eyes, military, military uniform, facial hair, stubble"
    },
    "class_type": "easy positive",
    "_meta": {
      "title": "prompt"
    }
  },
  "311": {
    "inputs": {
      "text": "monochrome, greyscale, black and white, yellowing, Noise, spots, cracks",
      "clip": [
        "297",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "313": {
    "inputs": {
      "width": [
        "300",
        0
      ],
      "height": [
        "300",
        0
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "292",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "309:0": {
    "inputs": {
      "model_name": "4xNomos8kSCHAT-L.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "309:1": {
    "inputs": {
      "upscale_model": [
        "309:0",
        0
      ],
      "image": [
        "302",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "301:0": {
    "inputs": {
      "control_net_name": "xinsir_cn_union_sdxl_1.0_promax.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "301:1": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "304",
        0
      ],
      "negative": [
        "311",
        0
      ],
      "control_net": [
        "301:0",
        0
      ],
      "image": [
        "302",
        0
      ],
      "vae": [
        "297",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "251:0": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "251:1": {
    "inputs": {
      "style_model_name": "flux1-redux-dev.safetensors"
    },
    "class_type": "StyleModelLoader",
    "_meta": {
      "title": "Load Style Model"
    }
  },
  "251:2": {
    "inputs": {
      "downsampling_factor": 1,
      "downsampling_function": "area",
      "mode": "keep aspect ratio",
      "weight": 1,
      "autocrop_margin": 0.05,
      "conditioning": [
        "112",
        0
      ],
      "style_model": [
        "251:1",
        0
      ],
      "clip_vision": [
        "251:0",
        0
      ],
      "image": [
        "292",
        0
      ]
    },
    "class_type": "ReduxAdvanced",
    "_meta": {
      "title": "ReduxAdvanced"
    }
  },
  "240:0": {
    "inputs": {
      "control_net_name": "flux.1-dev_controlnet_upscaler.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "240:1": {
    "inputs": {
      "strength": 0.7000000000000001,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "251:2",
        0
      ],
      "negative": [
        "238",
        0
      ],
      "control_net": [
        "240:0",
        0
      ],
      "image": [
        "292",
        0
      ],
      "vae": [
        "108",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "217:0": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "217:1": {
    "inputs": {
      "noise_seed": 683531140777675
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "217:2": {
    "inputs": {
      "scheduler": "normal",
      "steps": 28,
      "denoise": 1,
      "model": [
        "187",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "217:3": {
    "inputs": {
      "model": [
        "187",
        0
      ],
      "conditioning": [
        "240:1",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "217:4": {
    "inputs": {
      "noise": [
        "217:1",
        0
      ],
      "guider": [
        "217:3",
        0
      ],
      "sampler": [
        "217:0",
        0
      ],
      "sigmas": [
        "217:2",
        0
      ],
      "latent_image": [
        "208",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "wavespeed"
    }
  }
}