{
  "30": {
    "inputs": {
      "image": "11-å†™å®žæ‹Ÿäººå…”-è‡ªåŠ¨è‰²å½©å¹³è¡¡ä¼šæ¨¡ç³Š.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "i2i_ip_image1"
    }
  },
  "138": {
    "inputs": {
      "images": [
        "207",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "SaveImageWebsocket"
    }
  },
  "166": {
    "inputs": {
      "seed": [
        "196",
        6
      ],
      "steps": [
        "196",
        7
      ],
      "cfg": [
        "196",
        8
      ],
      "sampler_name": "euler_ancestral_cfg_pp",
      "scheduler": "sgm_uniform",
      "denoise": 1,
      "model": [
        "174",
        0
      ],
      "positive": [
        "193:1",
        0
      ],
      "negative": [
        "193:1",
        1
      ],
      "latent_image": [
        "171",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "167": {
    "inputs": {
      "text": [
        "198",
        0
      ],
      "clip": [
        "173",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "168": {
    "inputs": {
      "samples": [
        "166",
        0
      ],
      "vae": [
        "173",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "171": {
    "inputs": {
      "pixels": [
        "205",
        0
      ],
      "vae": [
        "173",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "173": {
    "inputs": {
      "ckpt_name": "LEOSAM_HelloWorldXL_70.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "base_model"
    }
  },
  "174": {
    "inputs": {
      "lora_name": "Hyper-SDXL-8steps-lora.safetensors",
      "strength_model": 1,
      "model": [
        "173",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "177": {
    "inputs": {
      "text": [
        "196",
        5
      ],
      "clip": [
        "173",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "negative_prompt"
    }
  },
  "179": {
    "inputs": {
      "width": 512,
      "height": 512,
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "30",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "181": {
    "inputs": {
      "width": [
        "196",
        1
      ],
      "height": [
        "196",
        1
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "194:1",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "182": {
    "inputs": {
      "blur_radius": 4,
      "sigma": 2,
      "image": [
        "181",
        0
      ]
    },
    "class_type": "ImageBlur",
    "_meta": {
      "title": "Image Blur"
    }
  },
  "196": {
    "inputs": {
      "clip_skip": -1,
      "width": 1024,
      "height": 1024,
      "swap": false,
      "batch_size": 1,
      "positive": "",
      "negative": "",
      "seed": 1123928013424186,
      "steps": 9,
      "cfg": 1.3,
      "denoise": 1
    },
    "class_type": "Co_Input_Zho",
    "_meta": {
      "title": "i2i_overall_input"
    }
  },
  "197": {
    "inputs": {
      "prompt": [
        "202",
        0
      ],
      "find1": "noise",
      "replace1": "",
      "find2": "spots",
      "replace2": "",
      "find3": "cracks",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "198": {
    "inputs": {
      "prompt": [
        "197",
        0
      ],
      "find1": "incomplete",
      "replace1": "",
      "find2": "scratch",
      "replace2": "",
      "find3": "crack",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "199": {
    "inputs": {
      "prompt": [
        "201",
        0
      ],
      "find1": "old picture",
      "replace1": "",
      "find2": "old portrait",
      "replace2": "",
      "find3": "old image",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "200": {
    "inputs": {
      "prompt": [
        "196",
        4
      ],
      "find1": "photograph",
      "replace1": "photo",
      "find2": "old photo",
      "replace2": "",
      "find3": "",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "201": {
    "inputs": {
      "prompt": [
        "200",
        0
      ],
      "find1": "vintage photo",
      "replace1": "",
      "find2": "old time photo",
      "replace2": "",
      "find3": "old style photo",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "202": {
    "inputs": {
      "prompt": [
        "199",
        0
      ],
      "find1": "fuzzy",
      "replace1": "",
      "find2": "blurry",
      "replace2": "clear, sharp, focused",
      "find3": "yellowing",
      "replace3": ""
    },
    "class_type": "easy promptReplace",
    "_meta": {
      "title": "PromptReplace"
    }
  },
  "205": {
    "inputs": {
      "brightness": 1,
      "contrast": 1.3,
      "saturation": 0,
      "image": [
        "182",
        0
      ]
    },
    "class_type": "LayerColor: BrightnessContrastV2",
    "_meta": {
      "title": "LayerColor: Brightness Contrast V2"
    }
  },
  "207": {
    "inputs": {
      "strength": 100,
      "brightness": 0,
      "contrast": 0,
      "saturation": 0,
      "red": 0,
      "green": 0,
      "blue": 0,
      "mode": "RGB",
      "image": [
        "208",
        0
      ]
    },
    "class_type": "LayerColor: AutoAdjustV2",
    "_meta": {
      "title": "LayerColor: AutoAdjust V2"
    }
  },
  "208": {
    "inputs": {
      "brightness": 1,
      "contrast": 1,
      "saturation": 0.7000000000000001,
      "image": [
        "168",
        0
      ]
    },
    "class_type": "LayerColor: BrightnessContrastV2",
    "_meta": {
      "title": "LayerColor: Brightness Contrast V2"
    }
  },
  "194:0": {
    "inputs": {
      "model_name": "4xNomos8kSCHAT-L.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "194:1": {
    "inputs": {
      "upscale_model": [
        "194:0",
        0
      ],
      "image": [
        "179",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "193:0": {
    "inputs": {
      "control_net_name": "xinsir_cn_union_sdxl_1.0_promax.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "193:1": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "167",
        0
      ],
      "negative": [
        "177",
        0
      ],
      "control_net": [
        "193:0",
        0
      ],
      "image": [
        "179",
        0
      ],
      "vae": [
        "173",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  }
}