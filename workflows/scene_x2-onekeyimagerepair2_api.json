{
  "107": {
    "inputs": {
      "text": "professional raw photo , realistic, analog photo, A 18-year-old Chinese  young man",
      "clip": [
        "123",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "prompt"
    }
  },
  "108": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "112": {
    "inputs": {
      "guidance": 2.5,
      "conditioning": [
        "107",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "123": {
    "inputs": {
      "clip_name1": "t5xxl_fp8_e4m3fn.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "187": {
    "inputs": {
      "object_to_patch": "diffusion_model",
      "residual_diff_threshold": 0.12,
      "start": 0,
      "end": 1,
      "max_consecutive_cache_hits": -1,
      "model": [
        "197",
        0
      ]
    },
    "class_type": "ApplyFBCacheOnModel",
    "_meta": {
      "title": "Apply First Block Cache"
    }
  },
  "189": {
    "inputs": {
      "samples": [
        "217:4",
        0
      ],
      "vae": [
        "108",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "196": {
    "inputs": {
      "unet_name": "flux-hyp8-Q5_K_M.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "197": {
    "inputs": {
      "model": [
        "196",
        0
      ]
    },
    "class_type": "DifferentialDiffusion",
    "_meta": {
      "title": "Differential Diffusion"
    }
  },
  "202": {
    "inputs": {
      "image": "åŽŸå§‹ç…§ç‰‡.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "i2i_ip_image1"
    }
  },
  "204": {
    "inputs": {
      "width": 512,
      "height": 512,
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "202",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "206": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "241:1",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "207": {
    "inputs": {
      "blur_radius": 2,
      "sigma": 2,
      "image": [
        "206",
        0
      ]
    },
    "class_type": "ImageBlur",
    "_meta": {
      "title": "Image Blur"
    }
  },
  "208": {
    "inputs": {
      "pixels": [
        "206",
        0
      ],
      "vae": [
        "108",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "219": {
    "inputs": {
      "text": "professional raw photo , realistic, analog photo, A 18-year-old Chinese  young man",
      "clip": [
        "220",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "prompt"
    }
  },
  "220": {
    "inputs": {
      "ckpt_name": "LEOSAM_HelloWorldXL_70.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "base_model"
    }
  },
  "221": {
    "inputs": {
      "lora_name": "Hyper-SDXL-8steps-lora.safetensors",
      "strength_model": 1,
      "model": [
        "220",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "222": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 0.9500000000000001,
      "positive": [
        "219",
        0
      ],
      "negative": [
        "227",
        0
      ],
      "control_net": [
        "223",
        0
      ],
      "image": [
        "207",
        0
      ],
      "vae": [
        "220",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "223": {
    "inputs": {
      "type": "auto",
      "control_net": [
        "228",
        0
      ]
    },
    "class_type": "SetUnionControlNetType",
    "_meta": {
      "title": "SetUnionControlNetType"
    }
  },
  "224": {
    "inputs": {
      "width": [
        "232",
        0
      ],
      "height": [
        "232",
        0
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "189",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "225": {
    "inputs": {
      "pixels": [
        "224",
        0
      ],
      "vae": [
        "220",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "226": {
    "inputs": {
      "seed": [
        "236",
        6
      ],
      "steps": [
        "248",
        0
      ],
      "cfg": 0.8,
      "sampler_name": "euler_ancestral_cfg_pp",
      "scheduler": "sgm_uniform",
      "denoise": 0.45,
      "model": [
        "221",
        0
      ],
      "positive": [
        "222",
        0
      ],
      "negative": [
        "222",
        1
      ],
      "latent_image": [
        "225",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "227": {
    "inputs": {
      "text": "Noise, spots, cracks",
      "clip": [
        "220",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "negative_prompt"
    }
  },
  "228": {
    "inputs": {
      "control_net_name": "xinsir_cn_union_sdxl_1.0_promax.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "229": {
    "inputs": {
      "purge_cache": true,
      "purge_models": true,
      "anything": [
        "231",
        0
      ]
    },
    "class_type": "LayerUtility: PurgeVRAM",
    "_meta": {
      "title": "LayerUtility: Purge VRAM"
    }
  },
  "230": {
    "inputs": {
      "images": [
        "231",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "result_image"
    }
  },
  "231": {
    "inputs": {
      "samples": [
        "226",
        0
      ],
      "vae": [
        "220",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "232": {
    "inputs": {
      "value": [
        "236",
        1
      ]
    },
    "class_type": "easy int",
    "_meta": {
      "title": "aspect_ratios_width"
    }
  },
  "235": {
    "inputs": {
      "value": 36
    },
    "class_type": "easy int",
    "_meta": {
      "title": "main_steps"
    }
  },
  "236": {
    "inputs": {
      "clip_skip": -1,
      "width": 1536,
      "height": 1024,
      "swap": false,
      "batch_size": 1,
      "positive": "",
      "negative": "",
      "seed": 1104130433580464,
      "steps": 10,
      "cfg": 30,
      "denoise": 1
    },
    "class_type": "Co_Input_Zho",
    "_meta": {
      "title": "i2i_overall_input"
    }
  },
  "238": {
    "inputs": {
      "conditioning": [
        "107",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "244": {
    "inputs": {
      "images": [
        "189",
        0
      ]
    },
    "class_type": "SaveImageWebsocket",
    "_meta": {
      "title": "mask_image1"
    }
  },
  "245": {
    "inputs": {
      "purge_cache": true,
      "purge_models": true,
      "anything": [
        "189",
        0
      ]
    },
    "class_type": "LayerUtility: PurgeVRAM",
    "_meta": {
      "title": "LayerUtility: Purge VRAM"
    }
  },
  "247": {
    "inputs": {
      "value": 28
    },
    "class_type": "easy int",
    "_meta": {
      "title": "K1 steps"
    }
  },
  "248": {
    "inputs": {
      "value": 8
    },
    "class_type": "easy int",
    "_meta": {
      "title": "K2 steps"
    }
  },
  "249": {
    "inputs": {
      "value": "a+b",
      "a": [
        "247",
        0
      ],
      "b": [
        "248",
        0
      ]
    },
    "class_type": "SimpleMath+",
    "_meta": {
      "title": "ðŸ”§ Simple Math"
    }
  },
  "250": {
    "inputs": {
      "input": [
        "249",
        0
      ],
      "output": ""
    },
    "class_type": "Display Int (rgthree)",
    "_meta": {
      "title": "all steps"
    }
  },
  "241:0": {
    "inputs": {
      "model_name": "4xNomos8kSCHAT-L.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "241:1": {
    "inputs": {
      "upscale_model": [
        "241:0",
        0
      ],
      "image": [
        "204",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "240:0": {
    "inputs": {
      "control_net_name": "flux.1-dev_controlnet_upscaler.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "240:1": {
    "inputs": {
      "strength": 0.7000000000000001,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "112",
        0
      ],
      "negative": [
        "238",
        0
      ],
      "control_net": [
        "240:0",
        0
      ],
      "image": [
        "207",
        0
      ],
      "vae": [
        "108",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "217:0": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "217:1": {
    "inputs": {
      "noise_seed": 169933447484194
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "217:2": {
    "inputs": {
      "scheduler": "simple",
      "steps": 28,
      "denoise": 1,
      "model": [
        "187",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "217:3": {
    "inputs": {
      "model": [
        "187",
        0
      ],
      "conditioning": [
        "240:1",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "217:4": {
    "inputs": {
      "noise": [
        "217:1",
        0
      ],
      "guider": [
        "217:3",
        0
      ],
      "sampler": [
        "217:0",
        0
      ],
      "sigmas": [
        "217:2",
        0
      ],
      "latent_image": [
        "208",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "wavespeed"
    }
  }
}